{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Transformer Models\n",
    "\n",
    "- pipeline() function for tasks such as text generation and classification\n",
    "- Transformer architecture\n",
    "- encoder, decoder, and encoder-decoder architectures and use cases\n",
    "\n",
    "\n",
    "## Introduction \n",
    "\n",
    "\n",
    "NLP focuses on **understanding everything related to human language**. not only to understand **single words individually**, but to be able to understand the **context of those words**.\n",
    "\n",
    "**Use case examples:**\n",
    "\n",
    "- **Classifying whole sentences**:     \n",
    "    - sentiment analysis, spam detection, grammar correction    \n",
    "- **Classifying each word in a sentence**:     \n",
    "    - part-of-speech tagging or POS tagging: identifying the grammatical components of a sentence such as nouns, verbs, and adjectives and assigning the appropriate grammatical tag to each word).    \n",
    "    - entity recognition or NER: task of identifying and classifying named entities such as persons, locations, organizations, and other proper nouns in a text. \n",
    "\n",
    "- **Generating text content**:\n",
    "    This task is often used for text completion, sentence generation, or to assess a model's understanding and ability to generate coherent and contextually appropriate text. known as masked language modeling or cloze-style language modeling. In this task, a model is given a text with certain words or tokens masked or removed, and the model's objective is to predict or generate the missing words or tokens.\n",
    "\n",
    "- **Extracting an answer from a text**:   \n",
    "    Question answering which can be extractive and abstractive:\n",
    "    - In extractive question answering, the model identifies and selects a span of text from the context that directly answers the question. The selected span is typically a contiguous sequence of words or tokens from the context.\n",
    "\n",
    "    - In abstractive question answering, the model generates a concise and coherent answer to the question based on the information in the context. The generated answer may not be an exact span of text from the context but rather a paraphrased or synthesized response.\n",
    "\n",
    "- **Generating a new sentence from an input text**: machine translation (MT) and text summarization\n",
    "\n",
    "\n",
    "NLP doesn't only deal with written text. It also works on understanding and solving difficult problems related to speech recognition and computer vision. For example, it can generate a written version of an audio recording or describe what's happening in an image."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with pipelines\n",
    "\n",
    "Transformer models are used to solve all kinds of NLP tasks. The HF Transformers library provides the functionality to **create** and **use the models** that have been shared by researchers. \n",
    "\n",
    "**pipeline() function** is the most basic object in the libaray, it connects a model with its necessary preprocessing and postprocessing steps."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the pipeline directly to input any text and get an output. The following code shows this with an example sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code **creates a pipeline** for **sentiment analysis** using the **pipeline function** from the **transformers module**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same with multiple sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9996962547302246},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997852444648743}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    [\"I've been feeling sick latley.\", \"This NLP project is sick!\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the model didnt pick up the meaning of word sick in the second sentence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using any model from the Hub in a pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask filling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named entity recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question answering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_HF-NLP-Notes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e271ed26a3bb9b9590c7e20b926699e380aa6724b9334935ca4b4823a968782"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
