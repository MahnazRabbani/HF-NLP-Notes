{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Transformer Models\n",
    "\n",
    "## Introduction \n",
    "\n",
    "- pipeline() function for tasks such as text generation and classification\n",
    "- Transformer architecture\n",
    "- encoder, decoder, and encoder-decoder architectures and use cases\n",
    "\n",
    "NLP focuses on understanding everything related to human language. not only to understand **single words individually**, but to be able to understand the **context of those words**.\n",
    "\n",
    "**Use case examples:**\n",
    "\n",
    "- Classifying whole sentences:     \n",
    "    sentiment analysis, spam detection, grammar correction    \n",
    "- Classifying each word in a sentence:     \n",
    "    part-of-speech tagging or POS tagging: identifying the grammatical components of a sentence such as nouns, verbs, and adjectives and assigning the appropriate grammatical tag to each word).    \n",
    "    entity recognition or NER: task of identifying and classifying named entities such as persons, locations, organizations, and other proper nouns in a text. \n",
    "\n",
    "- Generating text content:\n",
    "    This task is often used for text completion, sentence generation, or to assess a model's understanding and ability to generate coherent and contextually appropriate text. known as masked language modeling or cloze-style language modeling. In this task, a model is given a text with certain words or tokens masked or removed, and the model's objective is to predict or generate the missing words or tokens.\n",
    "\n",
    "- Extracting an answer from a text:   \n",
    "    Question answering which can be extractive and abstractive:\n",
    "    - In extractive question answering, the model identifies and selects a span of text from the context that directly answers the question. The selected span is typically a contiguous sequence of words or tokens from the context.\n",
    "\n",
    "    - In abstractive question answering, the model generates a concise and coherent answer to the question based on the information in the context. The generated answer may not be an exact span of text from the context but rather a paraphrased or synthesized response.\n",
    "\n",
    "- Generating a new sentence from an input text: machine translation (MT) and text summarization\n",
    "\n",
    "\n",
    "NLP doesn't only deal with written text. It also works on understanding and solving difficult problems related to speech recognition and computer vision. For example, it can generate a written version of an audio recording or describe what's happening in an image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2 (v3.11.2:878ead1ac1, Feb  7 2023, 10:02:41) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
